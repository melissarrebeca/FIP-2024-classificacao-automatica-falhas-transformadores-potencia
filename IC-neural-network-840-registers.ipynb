{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy, Precision, Recall, F1Score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura dos registros de treinamento\n",
    "csv_path_training_gases = \"C:/Users/melis/OneDrive/IC/IC-ML-Codes-3/.venv/separated_data/train_samples.csv\"\n",
    "with open(csv_path_training_gases, mode = 'r') as file:\n",
    "    csv_reader_training_gases = csv.reader(file)\n",
    "    next(csv_reader_training_gases)\n",
    "\n",
    "    train_samples = []\n",
    "    for row in csv_reader_training_gases:\n",
    "        train_samples.append(row)\n",
    "        \n",
    "csv_path_training_faults = \"C:/Users/melis/OneDrive/IC/IC-ML-Codes-3/.venv/separated_data/train_labels.csv\"\n",
    "with open(csv_path_training_faults, mode = 'r') as file:\n",
    "    csv_reader_training_faults = csv.reader(file)\n",
    "    next(csv_reader_training_faults)\n",
    "\n",
    "    train_labels = []\n",
    "    for row in csv_reader_training_faults:\n",
    "        train_labels.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalização dos gases\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)\n",
    "scaled_train_samples = np.array(scaled_train_samples)\n",
    "\n",
    "# normalização das falhas\n",
    "train_labels = train_labels.flatten()\n",
    "int_scaled_train_labels = (train_labels.astype(float)-1).astype(int)\n",
    "int_scaled_train_labels = np.array(int_scaled_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrutura da rede neural\n",
    "def create_functional_model():\n",
    "    inputs = Input(shape=(5,))\n",
    "    x = Dense(26, activation='relu')(inputs)\n",
    "    x = Dense(13, activation='relu')(inputs)\n",
    "    #x = Dense(10, activation='relu')(inputs)\n",
    "    outputs = Dense(7, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "functional_model = create_functional_model()\n",
    "history = functional_model.fit(scaled_train_samples, int_scaled_train_labels, epochs=1000, batch_size=25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotagem das métricas de treinamento\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    fig.suptitle('Métricas de Treinamento')\n",
    "\n",
    "    ax1.plot(epochs, acc, 'bo-', label='Acurácia de Treinamento')\n",
    "    ax1.set_title('Acurácia de Treinamento')\n",
    "    ax1.set_xlabel('Épocas')\n",
    "    ax1.set_ylabel('Acurácia')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(epochs, loss, 'ro-', label='Perda de Treinamento')\n",
    "    ax2.set_title('Perda de Treinamento')\n",
    "    ax2.set_xlabel('Épocas')\n",
    "    ax2.set_ylabel('Perda')\n",
    "    ax2.legend()\n",
    "\n",
    "    if 'val_accuracy' in history.history:\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        val_loss = history.history['val_loss']\n",
    "        ax1.plot(epochs, val_acc, 'g-', label='Acurácia de Validação')\n",
    "        ax2.plot(epochs, val_loss, 'm-', label='Perda de Validação')\n",
    "        ax1.legend()\n",
    "        ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura dos registros de teste\n",
    "csv_path_testing_gases = \"C:/Users/melis/OneDrive/IC/IC-ML-Codes-3/.venv/separated_data/test_samples.csv\"\n",
    "with open(csv_path_testing_gases, mode = 'r') as file:\n",
    "    csv_reader_testing_gases = csv.reader(file)\n",
    "    next(csv_reader_testing_gases)\n",
    "    \n",
    "    test_samples = []\n",
    "    for row in csv_reader_testing_gases:\n",
    "        test_samples.append(row)\n",
    "\n",
    "csv_path_testing_faults = \"C:/Users/melis/OneDrive/IC/IC-ML-Codes-3/.venv/separated_data/test_labels.csv\"\n",
    "with open(csv_path_testing_faults, mode = 'r') as file:\n",
    "    csv_reader_testing_faults = csv.reader(file)\n",
    "    next(csv_reader_testing_faults)\n",
    "    \n",
    "    test_labels = []\n",
    "    for row in csv_reader_testing_faults:\n",
    "        test_labels.append(row)\n",
    "\n",
    "# normalização dos gases de teste\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples)\n",
    "scaled_test_samples = np.array(scaled_test_samples)\n",
    "\n",
    "# normalização das falhas de teste\n",
    "test_labels = test_labels.flatten()\n",
    "int_scaled_test_labels = (test_labels.astype(float)-1).astype(int)\n",
    "int_scaled_test_labels = np.array(int_scaled_test_labels)\n",
    "\n",
    "# realizando predições com o modelo treinado\n",
    "y_pred = functional_model.predict(scaled_test_samples)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# avaliando o modelo\n",
    "test_loss, test_accuracy = functional_model.evaluate(scaled_test_samples, \n",
    "                                                   int_scaled_test_labels, \n",
    "                                                   verbose=0)\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.4f}\")\n",
    "print(f\"Perda no conjunto de teste: {test_loss:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(int_scaled_test_labels, y_pred_classes))\n",
    "\n",
    "# matriz de confusão\n",
    "cm = confusion_matrix(int_scaled_test_labels, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
